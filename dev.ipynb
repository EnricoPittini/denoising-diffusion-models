{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, ToTensor, RandomResizedCrop\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10, MNIST, Flowers102\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: %s' % device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.diffusionDataset import DiffusionDataset\n",
    "\n",
    "\n",
    "image_size = (128, 128)\n",
    "batch_size = 64\n",
    "#variance_schedule = np.ones(20)*0.0011\n",
    "variance_schedule = np.linspace(1e-3, 2e-2, 1000)       # from Ho et al. (2020)\n",
    "#alpha_t = np.cos((t/T+s)/(1+s)*np.pi/2)**2             # from Nichol & Dhariwal (2021)\n",
    "\n",
    "\n",
    "dataset_flowers = Flowers102(root='datasets',\n",
    "                  download=True)\n",
    "\n",
    "dataset = DiffusionDataset(data=dataset_flowers,\n",
    "                           variance_schedule=variance_schedule,\n",
    "                           transform=Compose([ToTensor(),\n",
    "                                            RandomResizedCrop(image_size)]))\n",
    "\n",
    "data_loader = DataLoader(dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         pin_memory=True,\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at some elements in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(im_n, t), noise = next(iter(data_loader))\n",
    "im_n = im_n[0]\n",
    "t = t[0]\n",
    "noise = noise[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.diffusionDataset import get_original_image\n",
    "\n",
    "im = get_original_image(im_n, noise, t, variance_schedule)\n",
    "\n",
    "print(f\"Forward diffusion step at stage t = {t}.\")\n",
    "\n",
    "w, h, dpi = 1500, 500, 100\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "ax[0].imshow(im_n.permute(1, 2, 0))\n",
    "ax[0].set_title('Noisy image')\n",
    "ax[1].imshow(noise.permute(1, 2, 0))\n",
    "ax[1].set_title('Noise')\n",
    "ax[2].imshow(im.permute(1, 2, 0))\n",
    "ax[2].set_title('Actual image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the variance schedule and $\\bar{\\alpha}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.diffusionDataset import get_alpha_bar\n",
    "\n",
    "T = 1000\n",
    "t = np.arange(T+1)\n",
    "s = 1e-3\n",
    "\n",
    "alpha_bar = get_alpha_bar(variance_schedule)\n",
    "\n",
    "w, h, dpi = 1000, 500, 100\n",
    "fig, ax1 = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.plot(variance_schedule, color='C0')\n",
    "ax2.plot(alpha_bar, color='C1')\n",
    "\n",
    "ax1.set_xlabel('t/T')\n",
    "ax1.set_ylabel('$beta_t$')\n",
    "ax2.set_ylabel('$alpha_t$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "And load previously saved weights if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.firstModel import FirstModel\n",
    "from models.secondModel import SecondModelSum, SecondModelConcat\n",
    "\n",
    "net = FirstModel(img_shape=(3,)+image_size, device=device)\n",
    "net.to(device)\n",
    "\n",
    "#net.load_state_dict(torch.load('weights/weights_FirstModel.pth'))\n",
    "\n",
    "training_loss_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on random input to see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (1, 3, 128, 128)\n",
    "input = torch.randn(input_size).to(device)\n",
    "output = net(input, torch.Tensor(1).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.training import training\n",
    "\n",
    "training_loss_list = training(net=net,\n",
    "                              data_loader=data_loader,\n",
    "                              loss_function=torch.nn.MSELoss(),\n",
    "                              epochs=5,\n",
    "                              device=device,\n",
    "                              training_loss_list=training_loss_list)\n",
    "plt.plot(training_loss_list)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save weights if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net.state_dict(), 'weights/weights_SecondModelSum.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.reconstruction import reconstruct_image_from_noise\n",
    "from utils.eval import visualize_single_reconstruction\n",
    "\n",
    "(noisy_image_batch, t_batch), noise_batch = next(iter(data_loader))\n",
    "i = np.argmin(t_batch.numpy())\n",
    "\n",
    "noisy_image = noisy_image_batch.numpy()[i]\n",
    "t = t_batch.numpy()[i]\n",
    "noise = noise_batch.numpy()[i]\n",
    "\n",
    "# true original image\n",
    "original_image = reconstruct_image_from_noise(noisy_image=noisy_image,\n",
    "                                              noise=noise,\n",
    "                                              t=t,\n",
    "                                              variance_schedule=variance_schedule)\n",
    "\n",
    "print(f't = {t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize results on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_single_reconstruction(net, original_image, noisy_image, t, variance_schedule, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparisons on single images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FirstModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.firstModel import FirstModel\n",
    "\n",
    "net = FirstModel(img_shape=(3,)+image_size, device=device)\n",
    "net.load_state_dict(torch.load('weights/weights_FirstModel.pth'))\n",
    "net.to(device)\n",
    "\n",
    "visualize_single_reconstruction(net, original_image, noisy_image, t, variance_schedule, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SecondModelSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.secondModel import SecondModelSum\n",
    "\n",
    "net = SecondModelSum(img_shape=(3,)+image_size, device=device)\n",
    "net.load_state_dict(torch.load('weights/weights_SecondModelSum.pth'))\n",
    "net.to(device)\n",
    "\n",
    "visualize_single_reconstruction(net, original_image, noisy_image, t, variance_schedule, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SecondModelConcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.secondModel import SecondModelConcat\n",
    "\n",
    "net = SecondModelConcat(img_shape=(3,)+image_size, device=device)\n",
    "net.load_state_dict(torch.load('weights/weights_SecondModelConcat.pth'))\n",
    "net.to(device)\n",
    "\n",
    "visualize_single_reconstruction(net, original_image, noisy_image, t, variance_schedule, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fc0ed74a087944f7d4394f4d91ee1483def030b33d45c86fb544dde79387957"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
