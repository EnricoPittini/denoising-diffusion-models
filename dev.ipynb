{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import Compose, ToTensor, RandomResizedCrop\n",
    "from torchvision.datasets import CIFAR10, MNIST, Flowers102\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: %s' % device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.diffusionDataset import DiffusionDataset\n",
    "\n",
    "\n",
    "image_size = (128, 128)\n",
    "batch_size = 16\n",
    "#variance_schedule = np.ones(20)*0.0011\n",
    "variance_schedule = np.linspace(0, 2e-2, 1000)       # from Ho et al. (2020)\n",
    "#alpha_t = np.cos((t/T+s)/(1+s)*np.pi/2)**2             # from Nichol & Dhariwal (2021)\n",
    "\n",
    "\n",
    "dataset_flowers = Flowers102(root='datasets',\n",
    "                  download=True)\n",
    "\n",
    "dataset = DiffusionDataset(data=dataset_flowers,\n",
    "                           variance_schedule=variance_schedule,\n",
    "                           transform=Compose([ToTensor(),\n",
    "                                            RandomResizedCrop(image_size)]))\n",
    "\n",
    "data_loader = DataLoader(dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         pin_memory=True,\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at some elements in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.reconstruction import reconstruct_image_from_noise\n",
    "\n",
    "(im_n, t), noise = next(iter(data_loader))\n",
    "im_n = im_n[0]\n",
    "t = t.numpy()[0]\n",
    "noise = noise[0]\n",
    "\n",
    "im = reconstruct_image_from_noise(im_n, noise, t, variance_schedule)\n",
    "\n",
    "print(f\"Forward diffusion step at stage t = {t}.\")\n",
    "\n",
    "w, h, dpi = 1500, 500, 100\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "ax[0].imshow(im_n.permute(1, 2, 0).clip(0, 1))\n",
    "ax[0].set_title('Noisy image')\n",
    "ax[1].imshow(noise.permute(1, 2, 0).clip(0, 1))\n",
    "ax[1].set_title('Noise')\n",
    "ax[2].imshow(im.permute(1, 2, 0).clip(0, 1))\n",
    "ax[2].set_title('Actual image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the variance schedule and $\\bar{\\alpha}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.diffusionDataset import get_alpha_bar\n",
    "\n",
    "T = 1000\n",
    "t = np.arange(T+1)\n",
    "s = 1e-3\n",
    "\n",
    "alpha_bar = get_alpha_bar(variance_schedule)\n",
    "\n",
    "w, h, dpi = 1000, 500, 100\n",
    "fig, ax1 = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.set_xlabel('t/T')\n",
    "\n",
    "color = 'C1'\n",
    "ax1.plot(alpha_bar, color=color)\n",
    "ax1.set_ylabel(r'$\\bar{\\alpha}_t$', color=color)\n",
    "ax2.spines['left'].set_color(color)\n",
    "ax1.tick_params(axis='y', colors=color)\n",
    "\n",
    "color = 'C0'\n",
    "ax2.plot(variance_schedule, color=color)\n",
    "ax2.set_ylabel(r'$\\beta_t$', color=color)\n",
    "ax2.spines['right'].set_color(color)\n",
    "ax2.tick_params(axis='y', colors=color)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.firstModel import FirstModel\n",
    "from models.secondModel import *\n",
    "from utils.training import train_model\n",
    "\n",
    "net = SecondModelConcatFC(img_shape=(3,)+image_size, device=device)\n",
    "\n",
    "epochs = 30\n",
    "additional_info = {'batch_size': batch_size,\n",
    "                   'image_size': image_size,\n",
    "                   'variance_schedule': variance_schedule\n",
    "                  }\n",
    "\n",
    "checkpoint_dict = train_model(net=net,\n",
    "                              data_loader=data_loader,\n",
    "                              loss_function=torch.nn.MSELoss(),\n",
    "                              epochs=epochs,\n",
    "                              device=device,\n",
    "                              checkpoint_folder='checkpoints/' + f'{type(net)}'.split('.')[-1][:-2],\n",
    "                              clear_previous_checkpoints=True,\n",
    "                              additional_info=additional_info)\n",
    "\n",
    "plt.plot(checkpoint_dict['loss_history'], 'o-')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(checkpoint_dict['loss_history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size_test = (512, 512)\n",
    "batch_size_test = 1\n",
    "\n",
    "dataset_test = DiffusionDataset(data=dataset_flowers,\n",
    "                                variance_schedule=variance_schedule,\n",
    "                                transform=Compose([ToTensor(),\n",
    "                                                   RandomResizedCrop(image_size_test)]))\n",
    "\n",
    "data_loader_test = DataLoader(dataset_test,\n",
    "                              batch_size=batch_size,\n",
    "                              pin_memory=True,\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.reconstruction import reconstruct_image_from_noise\n",
    "from utils.eval import visualize_single_reconstruction\n",
    "\n",
    "(noisy_image_batch, t_batch), noise_batch = next(iter(data_loader_test))\n",
    "i = np.argmin(t_batch.numpy())\n",
    "\n",
    "noisy_image = noisy_image_batch.numpy()[i]\n",
    "t = t_batch.numpy()[i]\n",
    "noise = noise_batch.numpy()[i]\n",
    "\n",
    "# true original image\n",
    "original_image = reconstruct_image_from_noise(noisy_image=noisy_image,\n",
    "                                              noise=noise,\n",
    "                                              t=t,\n",
    "                                              variance_schedule=variance_schedule)\n",
    "\n",
    "orig_name = \"flower\"\n",
    "\n",
    "print(f't = {t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a benchmark image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "from utils.diffusionDataset import get_alpha_bar\n",
    "from utils.eval import visualize_single_reconstruction\n",
    "\n",
    "original_image = np.asarray(image.imread('test_pictures/ship.jpg'), dtype=np.float32)/255\n",
    "orig_name = \"ship\"\n",
    "\n",
    "# original_image = np.asarray(image.imread('test_pictures/flower_1.jpg'), dtype=np.float32)/255\n",
    "# orig_name = \"flower_1\"\n",
    "\n",
    "#original_image = np.asarray(image.imread('test_pictures/flower_2.jpg'), dtype=np.float32)/255\n",
    "#orig_name = \"flower_2\"\n",
    "\n",
    "original_image = original_image.transpose(2, 0, 1)\n",
    "\n",
    "image_size_test = original_image.shape[1:]\n",
    "\n",
    "t = 25\n",
    "\n",
    "a = get_alpha_bar(variance_schedule)[t]\n",
    "noisy_image = np.sqrt(a)*original_image + np.sqrt(1-a)*np.random.normal(size=original_image.shape)\n",
    "noisy_image = noisy_image.clip(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparisons on single images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FirstModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.firstModel import FirstModel\n",
    "from utils.eval import visualize_single_reconstruction, load_weights\n",
    "\n",
    "net = FirstModel(img_shape=(3,)+image_size_test, device=device)\n",
    "load_weights(net, 'checkpoints/FirstModel/checkpoint.ckpt')\n",
    "net.to(device)\n",
    "\n",
    "visualize_single_reconstruction(net, original_image, noisy_image, t, variance_schedule, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SecondModelSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.secondModel import SecondModelSum\n",
    "from utils.eval import visualize_single_reconstruction, load_weights\n",
    "\n",
    "net = SecondModelSum(img_shape=(3,)+image_size_test, device=device)\n",
    "load_weights(net, 'checkpoints/SecondModelSum/checkpoint.ckpt')\n",
    "net.to(device)\n",
    "\n",
    "visualize_single_reconstruction(net, original_image, noisy_image, t, variance_schedule, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SecondModelConcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.secondModel import SecondModelConcat\n",
    "from utils.eval import visualize_single_reconstruction, load_weights\n",
    "\n",
    "net = SecondModelConcat(img_shape=(3,)+image_size_test, device=device)\n",
    "net_name = f'{type(net)}'.split('.')[-1][:-2]\n",
    "\n",
    "load_weights(net, f'checkpoints/{net_name}/checkpoint_0024_best.ckpt')\n",
    "net.to(device)\n",
    "\n",
    "output_folder = f'result_pictures/{net_name}_{orig_name}_{t}'\n",
    "step = [1, 5]\n",
    "visualize_single_reconstruction(net, original_image, noisy_image, t, variance_schedule, device, output_folder=output_folder, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SecondModelConcatK2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.secondModel import SecondModelConcatK2\n",
    "from utils.eval import visualize_single_reconstruction, load_weights\n",
    "\n",
    "net = SecondModelConcatK2(img_shape=(3,)+image_size_test, device=device)\n",
    "net_name = f'{type(net)}'.split('.')[-1][:-2]\n",
    "\n",
    "load_weights(net, f'checkpoints/{net_name}/checkpoint_0029_best.ckpt')\n",
    "net.to(device)\n",
    "\n",
    "output_folder = f'result_pictures/{net_name}_{orig_name}_{t}'\n",
    "step = [1, 5]\n",
    "visualize_single_reconstruction(net, original_image, noisy_image, t, variance_schedule, device, output_folder=output_folder, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SecondModelConcatFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.secondModel import SecondModelConcatFC\n",
    "from utils.eval import visualize_single_reconstruction, load_weights\n",
    "\n",
    "net = SecondModelConcatFC(img_shape=(3,)+image_size_test, device=device)\n",
    "net_name = f'{type(net)}'.split('.')[-1][:-2]\n",
    "\n",
    "load_weights(net, f'checkpoints/{net_name}/checkpoint_0028_best.ckpt')\n",
    "net.to(device)\n",
    "\n",
    "output_folder = f'result_pictures/{net_name}_{orig_name}_{t}'\n",
    "step = [1, 5]\n",
    "visualize_single_reconstruction(net, original_image, noisy_image, t, variance_schedule, device, output_folder=output_folder, step=step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fc0ed74a087944f7d4394f4d91ee1483def030b33d45c86fb544dde79387957"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
